{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Libraries for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"/Users/jeremyperez/Jupyter/NSL-KDD/KDDTrain+.csv\") \n",
    "testData = pd.read_csv(\"/Users/jeremyperez/Jupyter/NSL-KDD/KDDTest+.csv\")\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Dependent and independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = trainData.iloc[:,:-2].values # Get all the rows and all the clums except all the colums - 2\n",
    "Y = trainData.iloc[:,41].values # Get all the rows and the colum number 42\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "#Dummy encoding\n",
    "#We use dummy Encoding to pervent the machine learning don't atribute the categorical data in order. \n",
    "\n",
    "# Encoding the categorical data\n",
    "# Encoding the Independent Variable\n",
    "labelencoder_X = LabelEncoder()\n",
    "\n",
    "X[:,1] = labelencoder_X.fit_transform(X[:,1])\n",
    "X[:,2] = labelencoder_X.fit_transform(X[:,2])\n",
    "X[:,3] = labelencoder_X.fit_transform(X[:,3])\n",
    "X[:,41] = labelencoder_X.fit_transform(X[:,41])\n",
    "columntransformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1,2,3,41])],remainder = 'passthrough')\n",
    "\n",
    "# Encoding the Dependent Variable\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Dependent and independent Variables\n",
    "X = trainData.iloc[:,[41,42]].values # Get all the rows and all the clums except all the colums - 2\n",
    "\n",
    "#Elbow method to find the best number of culster\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++',max_iter = 300,n_init = 10,random_state = 0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "#5 clusters \n",
    "\n",
    "#Applying K-mea(n_clusters = 5)\n",
    "kmeans = KMeans(n_clusters = 5, init = 'k-means++',max_iter = 300,n_init = 10,random_state = 0)\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual representation of the clusters\n",
    "plt.scatter(X[y_kmeans ==0,0],X[y_kmeans == 0,1], s = 100, c = 'red', label = 'cluster1')\n",
    "plt.scatter(X[y_kmeans ==1,0],X[y_kmeans == 1,1], s = 100, c = 'yellow', label = 'cluster2')\n",
    "plt.scatter(X[y_kmeans ==2,0],X[y_kmeans == 2,1], s = 100, c = 'cyan', label = 'cluster3')\n",
    "plt.scatter(X[y_kmeans ==3,0],X[y_kmeans == 3,1], s = 100, c = 'orange', label = 'cluster4')\n",
    "plt.scatter(X[y_kmeans ==4,0],X[y_kmeans == 4,1], s = 100, c = 'black', label = 'cluster5')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0],kmeans.cluster_centers_[:, 1],s = 300, c = 'purple', label = 'Centroids')\n",
    "plt.title('Clusters of Attacks')\n",
    "plt.xlabel('Numbers of Attacks')\n",
    "plt.ylabel('Types of Attacks')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Create three gaussian blobs to use as our clustering data.\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "###############################################################################\n",
    "# Scikit-learn implementation of DBSCAN\n",
    "#\n",
    "\n",
    "print 'Runing scikit-learn implementation...'\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "skl_labels = db.labels_\n",
    "\n",
    "# Scikit learn uses -1 to for NOISE, and starts cluster labeling at 0. I start\n",
    "# numbering at 1, so increment the skl cluster numbers by 1.\n",
    "for i in range(0, len(skl_labels)):\n",
    "    if not skl_labels[i] == -1:\n",
    "        skl_labels[i] += 1\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Did we get the same results?\n",
    "\n",
    "num_disagree = 0\n",
    "\n",
    "# Go through each label and make sure they match (print the labels if they \n",
    "# don't)\n",
    "for i in range(0, len(skl_labels)):\n",
    "    if not skl_labels[i] == my_labels[i]:\n",
    "        print 'Scikit learn:', skl_labels[i], 'mine:', my_labels[i]\n",
    "        num_disagree += 1\n",
    "\n",
    "if num_disagree == 0:\n",
    "    print 'PASS - All labels match!'\n",
    "else:\n",
    "    print 'FAIL -', num_disagree, 'labels don\\'t match.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
